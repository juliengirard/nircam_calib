{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "529305f9",
   "metadata": {},
   "source": [
    "# NRC-23 - Image Quality Verification by Filter   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6309d94b",
   "metadata": {},
   "source": [
    "## Notebook: Perform Aperture photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae105683",
   "metadata": {},
   "source": [
    "**Author**: Matteo Correnti, STScI Scientist II\n",
    "<br>\n",
    "**Created**: October, 2021\n",
    "<br>\n",
    "**Last Updated**: February, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1734507d",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "1. [Introduction](#intro)<br>\n",
    "2. [Setup](#setup)<br>\n",
    "    2.1 [Python imports](#py_imports)<br>\n",
    "    2.2 [Plotting functions imports](#matpl_imports)<br>\n",
    "    2.3 [PSF FWHM dictionary](#psf_fwhm)<br>\n",
    "3. [Import images to analyze](#data)<br>\n",
    "    3.1 [Select Detector/Filter to analyze](#sel_data)<br>\n",
    "    3.2 [Prepare images](#prepare_image)<br>\n",
    "4. [Perform aperture photometry](#ap_phot)<br>\n",
    "    4.1 [Calculate the background](#bkg)<br>\n",
    "    4.2 [Find sources in the image](#find)<br>\n",
    "    4.3 [Aperture photometry](#aperture)<br>\n",
    "    4.4 [Clean catalogs and add magnitudes](#clean_mag)<br>\n",
    "    4.5 [Add coordinates](#add_coord)<br>\n",
    "    4.6 [Add flag from DQ array (optional)](#add_flag)<br>\n",
    "    4.7 [Save catalogs](#save)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d25e74",
   "metadata": {},
   "source": [
    "1.<font color='white'>-</font>Introduction <a class=\"anchor\" id=\"intro\"></a>\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d25498",
   "metadata": {},
   "source": [
    "This notebook shows how to perform aperture photometry on NIRCam images.\n",
    "\n",
    "The first part of the notebook is relevant for the analysis of calibrated but not-rectified images (i.e., *cal.fits* image, level-2). For the analyis of calibrated and rectified images (i.e., *i2d.fits* image, level-3), see note at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f31d0f",
   "metadata": {},
   "source": [
    "2.<font color='white'>-</font>Setup <a class=\"anchor\" id=\"setup\"></a>\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84642986",
   "metadata": {},
   "source": [
    "In this section we import all the necessary Python packages and we define some plotting parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5130672b",
   "metadata": {},
   "source": [
    "### 2.1<font color='white'>-</font>Python imports<a class=\"anchor\" id=\"py_imports\"></a> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0fe027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import glob as glob\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.stats import sigma_clipped_stats, SigmaClip\n",
    "from astropy.table import Table\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "from photutils.detection import DAOStarFinder\n",
    "from photutils.background import MMMBackground, MADStdBackgroundRMS, Background2D\n",
    "from photutils import CircularAperture, CircularAnnulus, aperture_photometry\n",
    "\n",
    "import jwst\n",
    "from jwst.datamodels import ImageModel\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022b9186",
   "metadata": {},
   "source": [
    "### 2.2<font color='white'>-</font>Plotting function imports<a class=\"anchor\" id=\"matpl_imports\"></a> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a589d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import style, pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "plt.rcParams['image.origin'] = 'lower'\n",
    "plt.rcParams['axes.titlesize'] = plt.rcParams['axes.labelsize'] = 30\n",
    "plt.rcParams['xtick.labelsize'] = plt.rcParams['ytick.labelsize'] = 20\n",
    "\n",
    "font1 = {'family': 'helvetica', 'color': 'black', 'weight': 'normal', 'size': '12'}\n",
    "font2 = {'family': 'helvetica', 'color': 'black', 'weight': 'normal', 'size': '20'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed2358a",
   "metadata": {},
   "source": [
    "### 2.3<font color='white'>-</font>PSF FWHM dictionary<a class=\"anchor\" id=\"psf_fwhm\"></a> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a68660",
   "metadata": {},
   "source": [
    "The dictionary contains the NIRCam point spread function (PSF) FWHM, from the [NIRCam Point Spread Function](https://jwst-docs.stsci.edu/near-infrared-camera/nircam-predicted-performance/nircam-point-spread-functions) JDox page. The FWHM are calculated from the analysis of the expected NIRCam PSFs simulated with [WebbPSF](https://www.stsci.edu/jwst/science-planning/proposal-planning-toolbox/psf-simulation-tool). \n",
    "\n",
    "FWHM is used in the finding script to provide a first order discrimination between sources and spurious detections\n",
    "\n",
    "**Note**: this dictionary need to be updated once the values for the FWHM will be available for each detectors during commissioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408747fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = ['F070W', 'F090W', 'F115W', 'F140M', 'F150W2', 'F150W', 'F162M', 'F164N', 'F182M',\n",
    "           'F187N', 'F200W', 'F210M', 'F212N', 'F250M', 'F277W', 'F300M', 'F322W2', 'F323N',\n",
    "           'F335M', 'F356W', 'F360M', 'F405N', 'F410M', 'F430M', 'F444W', 'F460M', 'F466N', 'F470N', 'F480M']\n",
    "\n",
    "psf_fwhm = [0.987, 1.103, 1.298, 1.553, 1.628, 1.770, 1.801, 1.494, 1.990, 2.060, 2.141, 2.304, 2.341, 1.340,\n",
    "            1.444, 1.585, 1.547, 1.711, 1.760, 1.830, 1.901, 2.165, 2.179, 2.300, 2.302, 2.459, 2.507, 2.535, 2.574]\n",
    "\n",
    "dict_utils = {filters[i]: {'psf fwhm': psf_fwhm[i]} for i in range(len(filters))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f84b051",
   "metadata": {},
   "source": [
    "3.<font color='white'>-</font>Import images to analyze<a class=\"anchor\" id=\"data\"></a>\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bb6485",
   "metadata": {},
   "source": [
    "We load all the images and we create a dictionary that contains all of them, divided by detectors and filters. This is useful to check which detectors and filters are available and to perform the analysis presented in this notebook on a detector/filter base. \n",
    "\n",
    "We retrieve the NIRCam detector and filter from the image header. Note that for the LW channels, we transform the detector name derived from the header (**NRCBLONG**) to **NRCB5**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a0217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_images = {'NRCA1': {}, 'NRCA2': {}, 'NRCA3': {}, 'NRCA4': {}, 'NRCA5': {},\n",
    "               'NRCB1': {}, 'NRCB2': {}, 'NRCB3': {}, 'NRCB4': {}, 'NRCB5': {}}\n",
    "\n",
    "dict_filter_short = {}\n",
    "dict_filter_long = {}\n",
    "\n",
    "ff_short = []\n",
    "det_short = []\n",
    "det_long = []\n",
    "ff_long = []\n",
    "detlist_short = []\n",
    "detlist_long = []\n",
    "filtlist_short = []\n",
    "filtlist_long = []\n",
    "\n",
    "# define the right path for the directory containing the Level-2 (*cal.fits) images\n",
    "\n",
    "images_dir = '../Simulation/Pipeline_Outputs/Level2_Outputs'\n",
    "images = sorted(glob.glob(os.path.join(images_dir, \"*cal.fits\")))\n",
    "\n",
    "for image in images:\n",
    "\n",
    "    im = fits.open(image)\n",
    "    f = im[0].header['FILTER']\n",
    "    d = im[0].header['DETECTOR']\n",
    "    p = im[0].header['PUPIL']\n",
    "\n",
    "    if d == 'NRCBLONG':\n",
    "        d = 'NRCB5'\n",
    "    elif d == 'NRCALONG':\n",
    "        d = 'NRCA5'\n",
    "    else:\n",
    "        d = d\n",
    "    \n",
    "    if p == 'CLEAR':\n",
    "        f = f\n",
    "    else:\n",
    "        f = p\n",
    "    \n",
    "    wv = float(f[1:3])\n",
    "\n",
    "    if wv > 24:         \n",
    "        ff_long.append(f)\n",
    "        det_long.append(d)\n",
    "\n",
    "    else:\n",
    "        ff_short.append(f)\n",
    "        det_short.append(d)   \n",
    "\n",
    "    detlist_short = sorted(list(dict.fromkeys(det_short)))\n",
    "    detlist_long = sorted(list(dict.fromkeys(det_long)))\n",
    "\n",
    "    unique_list_filters_short = []\n",
    "    unique_list_filters_long = []\n",
    "\n",
    "    for x in ff_short:\n",
    "\n",
    "        if x not in unique_list_filters_short:\n",
    "\n",
    "            dict_filter_short.setdefault(x, {})\n",
    "                 \n",
    "    for x in ff_long:\n",
    "        if x not in unique_list_filters_long:\n",
    "            dict_filter_long.setdefault(x, {})   \n",
    "            \n",
    "    for d_s in detlist_short:\n",
    "        dict_images[d_s] = copy.deepcopy(dict_filter_short)\n",
    "\n",
    "    for d_l in detlist_long:\n",
    "        dict_images[d_l] = copy.deepcopy(dict_filter_long)\n",
    "\n",
    "    filtlist_short = sorted(list(dict.fromkeys(dict_filter_short)))\n",
    "    filtlist_long = sorted(list(dict.fromkeys(dict_filter_long)))\n",
    "\n",
    "print(\"Available Detectors for SW channel:\", detlist_short)\n",
    "print(\"Available Detectors for LW channel:\", detlist_long)\n",
    "print(\"Available SW Filters:\", filtlist_short)\n",
    "print(\"Available LW Filters:\", filtlist_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448e5c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in images:\n",
    "    \n",
    "    im = fits.open(image)\n",
    "    f = im[0].header['FILTER']\n",
    "    d = im[0].header['DETECTOR']\n",
    "    p = im[0].header['PUPIL']\n",
    "\n",
    "    if d == 'NRCBLONG':\n",
    "        d = 'NRCB5'\n",
    "    elif d == 'NRCALONG':\n",
    "        d = 'NRCA5'\n",
    "    else:\n",
    "        d = d\n",
    "    \n",
    "    if p == 'CLEAR':\n",
    "        f = f\n",
    "    else:\n",
    "        f = p\n",
    "\n",
    "    if len(dict_images[d][f]) == 0:\n",
    "        dict_images[d][f] = {'images': [image]}\n",
    "    else:\n",
    "        dict_images[d][f]['images'].append(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863b7b3f",
   "metadata": {},
   "source": [
    "### 3.1<font color='white'>-</font>Select detector/filter to analyze<a class=\"anchor\" id=\"sel_data\"></a> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b77d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "det = 'NRCB1'\n",
    "filt = 'F200W'\n",
    "\n",
    "num_images = len(dict_images[det][filt]['images'])\n",
    "images_original = dict_images[det][filt]['images']\n",
    "\n",
    "print('Number of images for detector {}, filter {}:'.format(det, filt), num_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a727da",
   "metadata": {},
   "source": [
    "### 3.2<font color='white'>-</font>Prepare images<a class=\"anchor\" id=\"prepare_image\"></a> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e905fd52",
   "metadata": {},
   "source": [
    "Before the images are ready to be analyzed we need to perform some steps. \n",
    "First, not all pixels should be used. We can use the Data Quality (DQ) flags to assess whether a pixel can be considered in calculations or not. [Here](https://jwst-pipeline.readthedocs.io/en/latest/jwst/references_general/references_general.html#data-quality-flags) you can find a description of the DQ flags.\n",
    "\n",
    "There is no one-size-fits-all solution for selecting pixels using the DQ flags. Here we use the following:\n",
    "\n",
    "- 0 = Good pixel\n",
    "- 2 = Pixel saturated during integration\n",
    "- 4 = Jump detected during integration\n",
    "- 6 = Combination of DQ flags 2 and 4\n",
    "\n",
    "If we want to use all the pixels in the image (except for nan and noughts) we can exclude this selection in the function below and use the mask created inside the functions). \n",
    "\n",
    "The unit of the Level-2 and Level-3 Images from the pipeline is MJy/sr (hence a surface brightness). The actual unit of the image can be checked from the header keyword **BUNIT**. The scalar conversion constant is copied to the header keyword **PHOTMJSR**, which gives the conversion from DN/s to megaJy/steradian. It is possible to revert back to DN/s setting `convert = True` in the function below. To apply the PAM correction, set the parameter `pam = True` in the function below.\n",
    "\n",
    "For images that have not been transformed into a distortion-free frame (i.e. not drizzled), a correction must be applied to account for the different on-sky pixel size across the field of view. A pixel area map (PAM), which is an image where each pixel value describes that pixel's area on the sky relative to the native plate scale, is used for this correction. In the stage 2 of the JWST pipeline, the PAM is copied into an image extension called **AREA** in the science data product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64440e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(image, pam=True, select_dq=False, units=False):\n",
    "    im = fits.open(image)\n",
    "    data_original = im[1].data\n",
    "    imh = im[1].header\n",
    "    area = im[4].data\n",
    "    dq = im[3].data\n",
    "    \n",
    "    if pam:\n",
    "    \n",
    "        print('Applying Pixel Area Map')\n",
    "    \n",
    "        data_pam = data_original * area\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        data_pam = data_original\n",
    "    \n",
    "    if units:\n",
    "        \n",
    "        print('Converting units from {0} to DN/s').format(imh['BUNIT'])\n",
    "        data = data_pam / imh['PHOTMJSR']\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        data = data_pam\n",
    "    \n",
    "    if select_dq:\n",
    "        \n",
    "        print('Selecting good pixels from DQ Array')\n",
    "        ok = np.zeros(data_original.shape, dtype='int')\n",
    "        for v in [0, 2, 4, 6]:\n",
    "            ok = ok + np.where(dq==v, 1, 0)\n",
    "\n",
    "        data[ok==0] = np.nan\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed7e6f7",
   "metadata": {},
   "source": [
    "4.<font color='white'>-</font>Perform Aperture photometry<a class=\"anchor\" id=\"ap_phot\"></a>\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a05d1c",
   "metadata": {},
   "source": [
    "More information on aperture photometry using Photutils can be found here: [Aperture Photometry](https://photutils.readthedocs.io/en/stable/aperture.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253a3cdd",
   "metadata": {},
   "source": [
    "### 4.1<font color='white'>-</font>Calculate the background<a class=\"anchor\" id=\"bkg\"></a> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b246ea59",
   "metadata": {},
   "source": [
    "We adopted as Background estimator the function [MMMBackground](https://photutils.readthedocs.io/en/stable/api/photutils.background.MMMBackground.html#photutils.background.MMMBackground), which calculates the background in an array using the DAOPHOT MMM algorithm, on the whole image (The background is calculated using a mode estimator of the form `(3 * median) - (2 * mean)`).\n",
    "\n",
    "When dealing with a variable background or when we want to perform a more detailed calculation of the background, we can set `var_bkg = True` and use the Photutils package [Background2D](https://photutils.readthedocs.io/en/stable/api/photutils.background.Background2D.html). The basic idea is to divide the image in NxM subregions, estimate the background in each region, and finally create the low-resolution background image with a median filter.\n",
    "\n",
    "The choice of the input parameters for the _Background2D_ class is delicate. Some of the key input parameters to remember are the following:\n",
    "- box_size : the size (in pixels) of the box in which to estimate the background;\n",
    "- filter_size : the size of the window of the 2D median filter applied to the image to obtain the low-resolution background map;\n",
    "- sigma_clip : the sigma-clipping parameters;\n",
    "- bkg_estimator : the method used to compute the background;\n",
    "- coverage_mask : the mask that tells if a pixel should be masked and not used in the computation.\n",
    "\n",
    "These parameters should be fine tuned for every image according to some characteristics of the scene you are looking at, for example, the size of the sources, level of crowding, background gradient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152d213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bkg(data, mask=None, select_dq=False, var_bkg=False):\n",
    "    \n",
    "    bkgrms = MADStdBackgroundRMS()\n",
    "    mmm_bkg = MMMBackground()\n",
    "    \n",
    "    if select_dq:\n",
    "    \n",
    "        mask = np.full(np.shape(data), False, dtype=bool)\n",
    "        mask[np.isnan(data)==True] = True\n",
    "        mask[np.isfinite(data)==False] = True\n",
    "    \n",
    "    else:\n",
    "        mask=mask\n",
    "    \n",
    "    if var_bkg:\n",
    "        print('Using 2D Background')\n",
    "        sigma_clip = SigmaClip(sigma=3.)\n",
    "\n",
    "        bkg = Background2D(data, (500, 500), filter_size=(3, 3), sigma_clip=sigma_clip, bkg_estimator=mmm_bkg,\n",
    "                           coverage_mask=mask, fill_value=0.0)\n",
    "\n",
    "        data_bkgsub = data.copy()\n",
    "        data_bkgsub = data_bkgsub - bkg.background\n",
    "\n",
    "        median = bkg.background_median\n",
    "        std = bkg.background_rms_median\n",
    "        print('Background median and rms using Background 2D:', median, std)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        \n",
    "        std = bkgrms(data)\n",
    "        bkg = mmm_bkg(data)\n",
    "        print('Background median and rms:', bkg, std)\n",
    "        data_bkgsub = data.copy()\n",
    "        data_bkgsub -= bkg\n",
    "\n",
    "    return data_bkgsub, std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed804383",
   "metadata": {},
   "source": [
    "### 4.2<font color='white'>-</font>Find sources in the image<a class=\"anchor\" id=\"find\"></a> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51ee744",
   "metadata": {},
   "source": [
    "To find sources in the image, we use the [DAOStarFinder](https://photutils.readthedocs.io/en/stable/api/photutils.detection.DAOStarFinder.html) function. \n",
    "\n",
    "[DAOStarFinder](https://photutils.readthedocs.io/en/stable/api/photutils.detection.DAOStarFinder.html) detects stars in an image using the DAOFIND ([Stetson 1987](https://ui.adsabs.harvard.edu/abs/1987PASP...99..191S/abstract)) algorithm. DAOFIND searches images for local density maxima that have a peak amplitude greater than `threshold` (approximately; threshold is applied to a convolved image) and have a size and shape similar to the defined 2D Gaussian kernel.\n",
    "\n",
    "**Important parameters**:\n",
    "\n",
    "* `threshold`: The absolute image value above which to select sources.\n",
    "* `fwhm`: The full-width half-maximum (FWHM) of the major axis of the Gaussian kernel in units of pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d968fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_stars(image, select_dq=False, det='NRCA1', filt='F070W', threshold=3, var_bkg=False):\n",
    "    \n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    threshold : float \n",
    "        The absolute image value above which to select sources.\n",
    "    \n",
    "    fwhm : float\n",
    "        The full-width half-maximum (FWHM) of the major axis of the Gaussian kernel in units of pixels.\n",
    "        \n",
    "    var_bkg : bool\n",
    "        Use Background2D (see description above)\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    print('Finding stars --- Detector: {d}, Filter: {f}'.format(f=filt, d=det))\n",
    "    \n",
    "    sigma_psf = dict_utils[filt]['psf fwhm']\n",
    "\n",
    "    print('FWHM for the filter {f}:'.format(f=filt), sigma_psf, \"px\")\n",
    "    \n",
    "    if select_dq:\n",
    "        \n",
    "        data = prepare_image(image, select_dq=select_dq)\n",
    "    \n",
    "        data_bkgsub, std = calc_bkg(data, select_dq=select_dq, var_bkg=var_bkg)\n",
    "    \n",
    "        daofind = DAOStarFinder(threshold=threshold * std, fwhm=sigma_psf, exclude_border=True)\n",
    "        found_stars = daofind(data_bkgsub)\n",
    "    \n",
    "    else:\n",
    "        data = prepare_image(image, select_dq=select_dq)\n",
    "        \n",
    "        zero_mask = np.where(data == 0,0,1)\n",
    "        nan_mask  = np.where(np.isnan(data),0,1)\n",
    "        zero_mask = nan_mask * zero_mask\n",
    "    \n",
    "        nan_mask = np.where(zero_mask == 0,True,False)\n",
    "        \n",
    "        data_bkgsub, std = calc_bkg(data, mask=nan_mask, select_dq=select_dq, var_bkg=var_bkg)\n",
    "    \n",
    "        daofind = DAOStarFinder(threshold=threshold * std, fwhm=sigma_psf, exclude_border=True)\n",
    "        found_stars = daofind(data_bkgsub, mask=nan_mask)\n",
    "        \n",
    "    \n",
    "    print('')\n",
    "    print('Number of sources found in the image:', len(found_stars))\n",
    "    print('-------------------------------------')\n",
    "    print('')\n",
    "    \n",
    "    return found_stars, data_bkgsub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85c1934",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "\n",
    "found_stars_tot = []\n",
    "\n",
    "for i, image in enumerate(images_original):\n",
    "    \n",
    "    print('Working on image: {}'.format(i + 1))\n",
    "    print('')\n",
    "    \n",
    "    found_stars, _ = find_stars(image, select_dq=False, det=det, filt=filt, threshold=5, var_bkg=True)\n",
    "    \n",
    "    found_stars_tot.append(found_stars)\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(\"Elapsed Time for finding stars:\", toc - tic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d01a5a4",
   "metadata": {},
   "source": [
    "### 4.3<font color='white'>-</font>Aperture photometry<a class=\"anchor\" id=\"aperture\"></a> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ac7a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aperture_phot(image, found_stars, select_dq=False, radius=[3.5], sky_in=7, sky_out=10):\n",
    "\n",
    "    positions = np.transpose((found_stars['xcentroid'], found_stars['ycentroid']))\n",
    "    \n",
    "    tic = time.perf_counter()\n",
    "\n",
    "    table_aper = Table()\n",
    "        \n",
    "    data = prepare_image(image, select_dq)\n",
    "\n",
    "    for rad in radius:\n",
    "        print(\"Performing aperture photometry for detector {2} - filter {1}; radius r = {0} px\".format(rad, filt, det))\n",
    "        rr = str(rad)\n",
    "        aperture = CircularAperture(positions, r=rad)\n",
    "        \n",
    "        annulus_aperture = CircularAnnulus(positions, r_in=sky_in, r_out=sky_out)\n",
    "        annulus_mask = annulus_aperture.to_mask(method='center')\n",
    "\n",
    "        local_sky_median = []\n",
    "        local_sky_stdev = []\n",
    "        \n",
    "        for mask in annulus_mask:\n",
    "            \n",
    "            annulus_data = mask.multiply(data)\n",
    "            ok =np.logical_and(mask.data > 0, np.isfinite(annulus_data))\n",
    "            if (np.sum(ok) >= 10):\n",
    "                annulus_data_1d = annulus_data[ok]\n",
    "                mean_sigclip, median_sigclip, stdev_sigclip = sigma_clipped_stats(annulus_data_1d, \n",
    "                                                                                 sigma=3.5, maxiters=5)\n",
    "                if mean_sigclip < 0 or median_sigclip == 0:\n",
    "                    median_sigclip = -99.99\n",
    "                    stdev_siglclip = -9.99\n",
    "            \n",
    "            else:\n",
    "                median_sigclip = -99.99\n",
    "                stdev_sigclip = -9.99\n",
    "            \n",
    "            local_sky_median.append(median_sigclip)\n",
    "            local_sky_stdev.append(stdev_sigclip)\n",
    "        \n",
    "        local_sky_median = np.array(local_sky_median)\n",
    "        local_sky_stdev = np.array(local_sky_stdev)\n",
    "        \n",
    "        if select_dq:        \n",
    "            \n",
    "            phot = aperture_photometry(data, aperture, method='exact')\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            zero_mask = np.where(data == 0,0,1)\n",
    "            nan_mask  = np.where(np.isnan(data),0,1)\n",
    "            zero_mask = nan_mask * zero_mask\n",
    "    \n",
    "            nan_mask = np.where(zero_mask == 0,True,False)\n",
    "            \n",
    "            phot = aperture_photometry(data, aperture, method='exact', mask=nan_mask)\n",
    "        \n",
    "        phot['annulus_median'] = local_sky_median\n",
    "        phot['aper_bkg'] = local_sky_median * aperture.area\n",
    "        phot['aper_sum_bkgsub'] = phot['aperture_sum'] - phot['aper_bkg']\n",
    "        \n",
    "        table_aper.add_column(phot['aperture_sum'], name='aper_sum_' + rr + 'px')\n",
    "        table_aper.add_column(phot['annulus_median'], name='annulus_median_'+ rr + 'px')\n",
    "        table_aper.add_column(phot['aper_bkg'], name='aper_bkg_' + rr + 'px')\n",
    "        table_aper.add_column(phot['aper_sum_bkgsub'], name='aper_sum_bkgsub_' + rr + 'px')\n",
    "        \n",
    "        error_poisson = np.sqrt(phot['aperture_sum'])\n",
    "        error_scatter_sky = aperture.area * local_sky_stdev**2\n",
    "        error_mean_sky = local_sky_stdev**2 * aperture.area**2 / annulus_aperture.area\n",
    "\n",
    "        fluxerr = np.sqrt(error_poisson + error_scatter_sky + error_mean_sky)\n",
    "  \n",
    "        table_aper.add_column(fluxerr, name='flux_err_' + rr + 'px')\n",
    "\n",
    "    toc = time.perf_counter()\n",
    "    print(\"Time Elapsed:\", toc - tic)\n",
    "\n",
    "    return table_aper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aeda1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_aper_tot = []\n",
    "radii = [3.0, 3.5]\n",
    "\n",
    "for i in np.arange(0,len(images_original),1):\n",
    "    table_aper = aperture_phot(images_original[i], found_stars_tot[i], select_dq=False, radius=radii, \n",
    "                              sky_in=10, sky_out=15)\n",
    "    table_aper_tot.append(table_aper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8114d950",
   "metadata": {},
   "source": [
    "### 4.4<font color='white'>-</font>Clean catalogs and add magnitudes<a class=\"anchor\" id=\"clean_mag\"></a> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa94a86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_aper_clean = []\n",
    "for i, table in enumerate(table_aper_tot):\n",
    "    \n",
    "    table['x'] = found_stars_tot[i]['xcentroid']\n",
    "    table['y'] = found_stars_tot[i]['ycentroid']\n",
    "    table['sharpness'] = found_stars_tot[i]['sharpness']\n",
    "    table['roundness1'] = found_stars_tot[i]['roundness1']\n",
    "    table['roundness2'] = found_stars_tot[i]['roundness2']\n",
    "    \n",
    "    \n",
    "    keep_good_stars = np.logical_and(np.isfinite(table['aper_sum_bkgsub_3.5px']), \n",
    "                                     table['annulus_median_3.5px']>0.)\n",
    "    \n",
    "    table_clean=table[keep_good_stars]\n",
    "    \n",
    "    for r in radii:\n",
    "        \n",
    "        mag = -2.5 * np.log10(table_clean['aper_sum_bkgsub_' + str(r) + 'px'])\n",
    "        emag = 1.086 * (table_clean['flux_err_' + str(r) + 'px'] / \n",
    "                        table_clean['aper_sum_bkgsub_' + str(r) + 'px'])\n",
    "        \n",
    "        table_clean['mag_'+ str(r) +'px'] = mag\n",
    "        table_clean['emag_' +str(r)+ 'px'] = emag        \n",
    "\n",
    "    table_aper_clean.append(table_clean)\n",
    "        \n",
    "    print('Original number of sources from Aperture Photometry', len(table))\n",
    "    print('Number of sources after cleaning the catalogs:', len(table_clean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067287b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(table_aper_clean) > 2:\n",
    "\n",
    "    nn = int(np.sqrt(len(table_aper_clean)))\n",
    "    figsize = (12, 12)\n",
    "    fig, ax = plt.subplots(nn, nn, figsize=figsize)\n",
    "\n",
    "    for ix in range(nn):\n",
    "        for iy in range(nn):\n",
    "        \n",
    "            i = ix * nn + iy\n",
    "            ax[nn - 1 - iy, ix].scatter(table_aper_tot[i]['x'], table_aper_tot[i]['y'], s=3)\n",
    "            ax[nn - 1 - iy, ix].scatter(table_aper_clean[i]['x'], table_aper_clean[i]['y'], s=3)\n",
    "            ax[nn - 1 - iy, ix].set_xlabel('X [px]', fontsize=15)\n",
    "            ax[nn - 1 - iy, ix].set_ylabel('Y [px]', fontsize=15)\n",
    "            \n",
    "            \n",
    "            plt.suptitle(det + ' - ' + filt, fontsize=20)\n",
    "            plt.tight_layout()\n",
    "else:\n",
    "    \n",
    "    plt.figure(figsize = (12, 6))\n",
    "    nn = 2 \n",
    "    for i in range(nn):\n",
    "        ax = plt.subplot(1, nn, i + 1)\n",
    "        \n",
    "        ax.scatter(table_aper_tot[i]['x'], table_aper_tot[i]['y'], s=3)\n",
    "        ax.scatter(table_aper_clean[i]['x'], table_aper_clean[i]['y'], s=3)\n",
    "        ax.set_xlabel('X [px]')\n",
    "        ax.set_ylabel('Y [px]')\n",
    "        plt.suptitle(det + ' - ' + filt, fontsize=20)\n",
    "        plt.tight_layout()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8643a4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(table_aper_clean) > 2:\n",
    "\n",
    "    nn = int(np.sqrt(len(table_aper_clean)))\n",
    "    plt.figure(figsize = (12, 12))\n",
    "    fig, ax = plt.subplots(nn, nn, figsize=figsize)\n",
    "\n",
    "    for ix in range(nn):\n",
    "        for iy in range(nn):\n",
    "        \n",
    "            i = ix * nn + iy\n",
    "            \n",
    "            ax[nn - 1 - iy, ix].scatter(table_aper_clean[i]['mag_3.0px'], table_aper_clean[i]['emag_3.0px'])\n",
    "            \n",
    "            xlim0 = -11\n",
    "            xlim1 = 0 \n",
    "            ylim0 = 0 \n",
    "            ylim1 = 5\n",
    "        \n",
    "            ax[nn - 1 - iy, ix].set_xlim(xlim0, xlim1)\n",
    "            ax[nn - 1 - iy, ix].set_ylim(ylim0, ylim1)\n",
    "\n",
    "            ax[nn - 1 - iy, ix].xaxis.set_major_locator(ticker.AutoLocator())\n",
    "            ax[nn - 1 - iy, ix].xaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "            ax[nn - 1 - iy, ix].yaxis.set_major_locator(ticker.AutoLocator())\n",
    "            ax[nn - 1 - iy, ix].yaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "\n",
    "            ax[nn - 1 - iy, ix].set_xlabel('mag ', fontsize=15)\n",
    "            ax[nn - 1 - iy, ix].set_ylabel('$\\delta$ mag', fontsize=15)\n",
    "        \n",
    "            plt.suptitle(det + ' - ' + filt, fontsize=20)\n",
    "            plt.tight_layout()\n",
    "else:\n",
    "    \n",
    "    plt.figure(figsize = (12, 6))\n",
    "    nn = 2 \n",
    "    for i in range(nn):\n",
    "        ax = plt.subplot(nn, 1, i + 1)\n",
    "        \n",
    "        ax.scatter(table_aper_clean[i]['mag_3.0px'], table_aper_clean[i]['emag_3.0px'], s=3)\n",
    "        ylim0 = 0 \n",
    "        ylim1 = 5\n",
    "        \n",
    "        ax.set_ylim(ylim0, ylim1)\n",
    "\n",
    "        ax.xaxis.set_major_locator(ticker.AutoLocator())\n",
    "        ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "        ax.yaxis.set_major_locator(ticker.AutoLocator())\n",
    "        ax.yaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "\n",
    "        ax.set_xlabel('mag ')\n",
    "        ax.set_ylabel('$\\delta$ mag')\n",
    "        plt.suptitle(det + ' - ' + filt, fontsize=20)\n",
    "        plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ac2a62",
   "metadata": {},
   "source": [
    "### 4.5<font color='white'>-</font>Add coordinates<a class=\"anchor\" id=\"add_coord\"></a> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2809577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_phot = []\n",
    "\n",
    "for image, table in zip(images_original, table_aper_clean):\n",
    "    \n",
    "    image_model = ImageModel(image)\n",
    "    \n",
    "    ra,dec = image_model.meta.wcs(table['x'], table['y'])\n",
    "    table['radec'] = SkyCoord(ra, dec, unit='deg')\n",
    "\n",
    "    table_phot.append(table)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d5570f",
   "metadata": {},
   "source": [
    "### 4.6<font color='white'>-</font>Add flag from DQ array (optional)<a class=\"anchor\" id=\"add_flag\"></a> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23bb89b",
   "metadata": {},
   "source": [
    "Run the cell below, if you used the DQ flags to mask some pixels and kept only those with DQ$=$0, 2, 4, 6. Although still perfectly usable, you might want to keep track of pixels that saturated during an integration or were hit by a cosmic ray. For this reason, we define a flag by checking all pixels within each aperture radius we used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168d554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, table in zip(images_original, table_phot):\n",
    "    \n",
    "    table['flag_'+str(r)] = np.zeros(len(table), dtype = int)\n",
    "    \n",
    "    for r in radii:\n",
    "        \n",
    "        for s in table:\n",
    "        \n",
    "            im = fits.open(image)\n",
    "            data = im[1].data\n",
    "            dq = im[3].data\n",
    "        \n",
    "            jmin = max(1,int(np.floor(s['y']-r)))\n",
    "            jmax = min(round(s['y']+r)+1,data.shape[0])\n",
    "            imin = max(1,int(np.floor(s['x']-r)))\n",
    "            imax = min(round(s['x']+r)+1,data.shape[1])\n",
    "        \n",
    "            if (np.sum(im[3].data[jmin:jmax,imin:imax]==6)>0):\n",
    "                s['flag_' + str(r)+'px'] = 6\n",
    "            elif (np.sum(im[3].data[jmin:jmax,imin:imax]==2)>0):\n",
    "                s['flag_' + str(r)+'px'] = 2\n",
    "            elif (np.sum(im[3].data[jmin:jmax,imin:imax]==4)>0):\n",
    "                s['flag_' + str(r)+'px'] = 4        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc3bb14",
   "metadata": {},
   "source": [
    "### 4.7<font color='white'>-</font>Save catalogs<a class=\"anchor\" id=\"save\"></a> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c59ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_phot_dir = 'AP_PHOT_OUTPUT/'\n",
    "\n",
    "if not os.path.exists(output_phot_dir):\n",
    "    os.makedirs(output_phot_dir)\n",
    "\n",
    "for i,table in enumerate(table_phot):\n",
    "    \n",
    "    num = str(i+1)\n",
    "    outname = 'ap_phot_%s_%s_%s.pkl' %(det, filt, num)\n",
    "\n",
    "    print('Aperture Photometry catalog output name:', outname)\n",
    "    tab = table.to_pandas()\n",
    "    tab.to_pickle(os.path.join(output_phot_dir, outname))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9931ae8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <h3><u><b>Aperture photometry on stage-3 images</b></u></h3>\n",
    "    \n",
    "This notebook can be adapted to perform aperture photometry on stage-3 (_i2d.fits_) images. In this case, with a few expedients the photometric calibration does not need additional files.\n",
    "    \n",
    "First, we choose an aperture radius from the aperture-correction reference file available in the <a href=\"https://jwst-crds.stsci.edu/\">JWST Calibration Reference Data System</a> (CRDS). For each filter (FILTER), and encircled-energy values (EEFRACTION), this file lists the aperture-correction values needed for correcting observed signals within a finite aperture to the estimated total signal for a source (APCORR), the aperture radius containing the EEFRACTION fraction of the total flux (RADIUS), the inner (SKYIN) and outer (SKYOUT) radii for the sky estimation. The APCORR value is a multiplicative correction that scales the measured flux to infinite aperture.\n",
    "\n",
    "If we perform aperture photometry using these values of RADIUS, SKYIN and SKYOUT, then, once corrected the flux for the finite aperture, the photometric calibration is straighforward. Indeed, as for stage-2 images, the pixel unit in the stage-3 images is MJy sr$^{-1}$. This is an advantage for the photometric calibration because we can directly obtain magnitudes in the AB system (<a href=\"https://ui.adsabs.harvard.edu/abs/1964ApJ...140..689O/abstract\">Oke 1964</a>; see also Sect. 7 of <a href=\"https://ui.adsabs.harvard.edu/abs/2005PASP..117.1049S/abstract\">Sirianni et al. 2005</a>). The AB magnitude is defined as:\n",
    "\n",
    "\\begin{equation*}\n",
    "    m_{\\rm AB} = -2.5 \\log_{10} f_\\nu - 48.60\n",
    "\\end{equation*}\n",
    "\n",
    "with $f_\\nu$ in erg s$^{-1}$ cm$^{-2}$ Hz$^{-1}$, or as:\n",
    "\n",
    "\\begin{equation*}\n",
    "    m_{\\rm AB} = -2.5 \\log_{10} f_\\nu + 8.90\n",
    "\\end{equation*}\n",
    "\n",
    "with $f_\\nu$ in Jansky. Therefore, we can simply transform our total flux in MJy sr$^{-1}$ by multiplying it by $10^6$ and by the average pixel area in steradian. The header keyword _PIXAR_SR_ contains the average pixel area in steradian; the corresponding value in the JWST data-model scheme is included in _meta.photometry.pixelarea_steradians_. This value is added in the flux (photometric) calibrations performed by the _Photom_ step of the _calwebb_image2_ pipeline.\n",
    "\n",
    "AB magnitudes can be converted to VEGA magnitudes by adding the AB-to-Vega magnitude offset available in the corresponding reference file in the CRDS.\n",
    "    \n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <h3><u><b>Warning 1</b></u></h3>\n",
    "\n",
    "The APCORR values include a correction for the sky-background subtraction obtained with the specific SKYIN and SKYOUT radii provided in the CRDS reference file. This correction takes into account the contribution of the PSF wings of the star to the local background. If different sky-background radii are used, the APCORR values cannot be used anymore. The best alternative option is to evaluate the sky background in an annulus far enough from the center of each star that the contribution of the PSF wings of the star to the local background is negligible, for example between 25 and 35 pixels as shown in this notebook. In this case, the total flux of a star can be obtained from the flux containging EEFRACTION of the total flux by multiplying it by EEFRACTION$^{-1}$.\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <h3><u><b>Warning 2</b></u></h3>\n",
    "\n",
    "All the values provided in the CRDS reference file are obtained for a single SW detector and for a PSF centered in the center of the array. \n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <h3><u><b>Warning 3</b></u></h3>\n",
    "\n",
    "No pixel-area map correction is needed with stage-3 images.\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18773ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
